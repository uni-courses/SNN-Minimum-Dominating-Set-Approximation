\section{Discussion}\label{sec:discussion}
The reliability of the results can be improved by running the algorithm on more and larger graphs. Running on the Loihi 2 using the Lava 0.4.0 Framework may facilitate this. 

The apparent non-linear growth of the energy consumption in terms of spikes is not expected for the brain adaptation implementation. This is not expected because the redundant neurons should either be inhibited once, or, if they take over from the dead neuron, repeat the exact same spike pattern the dead neuron would have given. This would result in an additive spike increase of roughly the SNN size, not in an exponentially growing multiple. After inspecting the spike behaviour, it is noted that some of the inhibition between neurons and redundant neurons does not stop over time. This causes unneeded spikes generation.

Even though no public SEE propagation mechanisms are known for the Loihi 2 at the time of writing, the representativeness of the simulation can be increased by taking transient effects, synaptic changes, neuron property changes and Von Neumann component malfunctions into account. The current form of redundancy that is implemented is still dependent on particular neuron properties, and no automated method for arbitrary LIF neuron redundancy is presented. A more intelligent adaptation mechanism may allow for a more active neural pathway redirection to realise equivalent robustness levels at a lower neuronal and synaptic overhead. 
%The discussion is used to put the/any radiation robustness differences between using a brain-inspired implementation and regular redundancy in neuromorphic architectures, into perspective. This perspective is generated by discussing the architecture comparison in terms of the characteristics described in \cref{subsec:discussion_performance_trade_off} to \cref{subsec:discussion_space_application_representation_accuracy}.

%\subsection{Performance Trade-Off}\label{subsec:discussion_performance_trade_off}
%\textit{Increasing the radiation resistance of a default neuromorphic implementation requires some effort. In this study, this effort is realised in the form of a brain-inspired implementation. Such an implementation comes at the cost of resources. In this case those resources are neurons, synapses and energy consumption. Since the comparison is made in terms of radiation robustness, it is important to determine whether it is not merely the consumption of extra resources that led to performance differences. In particular, for space applications, it is important to determine whether the resources that are consumed, for example the energy consumption, are worth the benefits. Each space mission will have its own trade-off in these terms, however, this subsection can shed some light on the trade-off costs. In essence a quantitative insight can be given in terms of performance enhancement and energy cost increases. Similarly, a quantitative insight can be provided in terms of performance enhancement, and the increase in required neurons/synapses and/or hardware mass (if the increase in neurons/synapses require a larger chip).}

%\subsection{Simulation vs Radiation Testing}
%\textit{If the radiation testing is performed softwarematically in this article submission, this section can be used to convey how portable these results are expected to be to practical radiation tests.}

%\subsection{Radiation Robustness of Traditional Hardware Elements}
%\textit{The potential bottleneck of traditional Von Neumann hardware elements in neuromorphic hardware, as introduced in \cref{subsec:results_traditional_hardware_element_performance} should be discussed in this section.}

%\subsection{Space Application Representation Accuracy}\label{subsec:discussion_space_application_representation_accuracy}
%\textit{Some context can be provided in this section to indicate how/up to what extent the radiation testing that is performed for this article submission applies to real space applications.}
% Explain actual space applications may be more AI and less optimisation.

\subsection{Population Coding}\label{subsec:population_coding}
Other encoding mechanisms than sparse coding may be considered to realise radiation robustness. For example,  in population coding, a population of neurons could be used to represent integer values instead of a single neuron. The \verb+spike_once+ neuron with a synaptic output weight of $x$ could be replaced by $x$ neurons along with $m$ excitatory controller neurons that verify whether each of those neurons is still functional. If part of the population dies, the controller neurons can excite parts of the population to compensate this loss. The $m$ controller neurons could inhibit each other and form a redundancy in the redundancy mechanism.

\subsection{Rate Coding}\label{subsec:rate_coding}
The first round of the algorithm by Alipour et al. has also been implemented using Lava V0.3.0 using a rate-coding approach, where the numbers are represented as a frequency. No radiation damage simulation has yet been performed on this implementation. However, it is expected that spike frequency modulation can be leveraged to mitigate radiation induced spike loss.

\subsection{Algorithm Selection}\label{subsec:algorithm_selection}
This work has focussed on a particular optimisation problem, it can be noted that clever algorithm selection (and/or design) for radiation robust SNNs may be used to exchange approximation accuracy for robustness. For example, instead of selecting an algorithm that breaks if a single neuron dies, one could consider shortest-path algorithms that automatically yield a longer path that works around the neuron death. Furthermore, selecting applications that are closer to natural brain functionalities, such as event-based vision, may facilitate brain adaptation mechanisms at a lower cost. For example, in some deep neural networks, neuron death may be a feature instead of a bug, as the retraining phase can in some cases be used to increase the generalisability of the network. % TODO: doubt: is this an example analogous to brain adaptation?

\subsection{Physical Testing}\label{subsec:physical_testing}
Many of the discussed brain adaptation implementations will fail if the boiler-plate architecture of the SNN suffer from SEEs. This issue can be resolved using fault-tolerance acceptance, redundancy and/or local shielding of boiler-plate architecture components, and by taking boiler-plate SEE propagation mechanisms into account in SNN design. The latter would require physical testing and/or detailed hardware analysis. Industry partners of the Intel Neuromorphic Research Community, such as ESA, NASA and Raytheon are also working on radiation robustness \cite{inrc_meeting} and may be able to share insight in the more detailed radiation effects on the Loihi 2 without incurring export license limitations.